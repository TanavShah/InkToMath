{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Copy of step2_train_ml_model.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EXyJkL4WnqyS"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kS_mq4yAlXHZ",
        "colab": {}
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r0WlLrJcnwWp"
      },
      "source": [
        "## Download and explore the MNIST dataset\n",
        "The MNIST database contains 60,000 training images and 10,000 testing images of handwritten digits. We will use the dataset to train our digit classification model.\n",
        "\n",
        "Each image in the MNIST dataset is a 28x28 grayscale image containing a digit from 0 to 9, and a label identifying which digit is in the image.\n",
        "![MNIST sample](https://github.com/khanhlvg/DigitClassifier/raw/master/images/mnist.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfyVd6a8Ihxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train=pd.read_csv('train_final.csv',index_col=False)\n",
        "labels=df_train[['784']]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHffj_X8I3H3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.drop(df_train.columns[[784]],axis=1,inplace=True)\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19Z27jqVJER-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=np.array(labels)\n",
        "cat=to_categorical(labels,num_classes=13)\n",
        "print(cat[0])\n",
        "cat.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULNXGUCBJPMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l=[]\n",
        "for i in range(47504):\n",
        "    l.append(np.array(df_train[i:i+1]).reshape(28,28))\n",
        "\n",
        "l = np.array(l)\n",
        "l = l/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IWgBGmaplzcp",
        "colab": {}
      },
      "source": [
        "# Define the model architecture\n",
        "print(np.array(l).shape)\n",
        "print(cat.shape)\n",
        "model = keras.Sequential([\n",
        "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  keras.layers.Conv2D(30, (5, 5), activation='relu'),\n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  keras.layers.Conv2D(15, (3, 3), activation='relu'),\n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  keras.layers.Dropout(0.2),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(128, activation='relu'),\n",
        "  keras.layers.Dense(50, activation='relu'),\n",
        "  keras.layers.Dense(13, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Define how to train the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Train the digit classification model\n",
        "model.fit(l, cat, epochs=10, batch_size=200,shuffle=True,verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WFHKkb7gcJei"
      },
      "source": [
        "Let's take a closer look at our model structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y7V6-UQqcuK-",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AWROBI4iv9fY"
      },
      "source": [
        "## Convert the Keras model to TensorFlow Lite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bV99Izwykb-J"
      },
      "source": [
        "Now as we have trained the digit classifer model, we will convert it to TensorFlow Lite format for mobile deployment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2fXStjR4mzkR",
        "colab": {}
      },
      "source": [
        "# Convert Keras model to TF Lite format.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_float_model = converter.convert()\n",
        "\n",
        "# Show model size in KBs.\n",
        "float_model_size = len(tflite_float_model) / 1024\n",
        "print('Float model size = %dKBs.' % float_model_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tfer6hI8ljEh"
      },
      "source": [
        "As we will deploy our model to a mobile device, we want our model to be as small and as fast as possible. **Quantization** is a common technique often used in on-device machine learning to shrink ML models. Here we will use 8-bit number to approximate our 32-bit weights, which in turn shrinks the model size by a factor of 4.\n",
        "\n",
        "See [TensorFlow documentation](https://www.tensorflow.org/lite/performance/post_training_quantization) to learn more about other quantization techniques."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yhY86SRTmtGC",
        "colab": {}
      },
      "source": [
        "# Re-convert the model to TF Lite using quantization.\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "# Show model size in KBs.\n",
        "quantized_model_size = len(tflite_quantized_model) / 1024\n",
        "print('Quantized model size = %dKBs,' % quantized_model_size)\n",
        "print('which is about %d%% of the float model size.'\\\n",
        "      % (quantized_model_size * 100 / float_model_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ItyEwAdCCVw6"
      },
      "source": [
        "## Download the TensorFlow Lite model\n",
        "\n",
        "Let's get our model and integrate it into an Android app.\n",
        "\n",
        "If you see an error when downloading mnist.tflite from Colab, try running this cell again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q_Z5yLxrwbpI",
        "colab": {}
      },
      "source": [
        "# Save the quantized model to file to the Downloads directory\n",
        "f = open('mnist_final_4.tflite', \"wb\")\n",
        "f.write(tflite_float_model)\n",
        "f.close()\n",
        "\n",
        "# Download the digit classification model\n",
        "from google.colab import files\n",
        "files.download('mnist_final_4.tflite')\n",
        "\n",
        "print('`mnist_final_4.tflite` has been downloaded')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}